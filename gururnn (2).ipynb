{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX3WUWb91oat",
        "outputId": "dc7cb948-b597-45aa-a43c-e41c29007acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mM1gO-QDzHR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Music Instrument/Indian Music Inst\"\n",
        "JSON_PATH = \"/content/drive/MyDrive/Music Instrument/data_10.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "\n",
        "\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're processing a genre sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            # process all audio files in genre sub-dir\n",
        "            for f in filenames:\n",
        "\n",
        "\t\t# load audio file\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sample_rate = librosa.load(file_path)\n",
        "\n",
        "                # process all segments of audio file\n",
        "                for d in range(num_segments):\n",
        "\n",
        "                    # calculate start and finish sample for current segment\n",
        "                    start = samples_per_segment * d\n",
        "                    finish = start + samples_per_segment\n",
        "\n",
        "                    # extract mfcc\n",
        "                    # mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc)\n",
        "                    mfcc=librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=40)\n",
        "                    mfcc = mfcc.T\n",
        "\n",
        "                    # store only mfcc feature with expected number of vectors\n",
        "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "\n",
        "    # save MFCCs to json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Music Instrument/data_10.json\"\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "\n",
        "\n",
        "    with open(data_path, \"r\") as fp:\n",
        "        data = json.load(fp)\n",
        "\n",
        "    X = np.array(data[\"mfcc\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def prepare_datasets(test_size, validation_size):\n",
        "\n",
        "    # load data\n",
        "    X, y = load_data(DATA_PATH)\n",
        "\n",
        "    # create train, validation and test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
        "\n",
        "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "\n",
        "\n",
        "    # build network topology\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 2 LSTM layers\n",
        "    model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(keras.layers.LSTM(64))\n",
        "\n",
        "    # dense layer\n",
        "    model.add(keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # get train, validation, test splits\n",
        "    X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)\n",
        "\n",
        "    # create network\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2]) # 130, 13\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # compile model\n",
        "    optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimiser,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=150)\n",
        "\n",
        "    # plot accuracy/error for training and validation\n",
        "    plot_history(history)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lmYgR8phHyqU",
        "outputId": "c9bfb50d-7670-42da-c17e-530f1cd1171f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 130, 64)           26880     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,714\n",
            "Trainable params: 64,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "35/35 [==============================] - 7s 40ms/step - loss: 2.2169 - accuracy: 0.2388 - val_loss: 2.0322 - val_accuracy: 0.5568\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 1.8111 - accuracy: 0.5748 - val_loss: 1.6222 - val_accuracy: 0.6337\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 1.4263 - accuracy: 0.6768 - val_loss: 1.2424 - val_accuracy: 0.6630\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 1.1009 - accuracy: 0.7135 - val_loss: 0.9518 - val_accuracy: 0.7070\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.8649 - accuracy: 0.7539 - val_loss: 0.7495 - val_accuracy: 0.7656\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.8044 - val_loss: 0.6070 - val_accuracy: 0.8205\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.5611 - accuracy: 0.8567 - val_loss: 0.5087 - val_accuracy: 0.8425\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.4662 - accuracy: 0.8806 - val_loss: 0.4417 - val_accuracy: 0.8681\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.4005 - accuracy: 0.9063 - val_loss: 0.3936 - val_accuracy: 0.8718\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.9164 - val_loss: 0.3566 - val_accuracy: 0.8864\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.3223 - accuracy: 0.9302 - val_loss: 0.3315 - val_accuracy: 0.8901\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.2773 - accuracy: 0.9376 - val_loss: 0.3279 - val_accuracy: 0.8864\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9357 - val_loss: 0.3052 - val_accuracy: 0.8901\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.2425 - accuracy: 0.9403 - val_loss: 0.2967 - val_accuracy: 0.8974\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.2204 - accuracy: 0.9486 - val_loss: 0.2653 - val_accuracy: 0.9194\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.2094 - accuracy: 0.9522 - val_loss: 0.2825 - val_accuracy: 0.9084\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1843 - accuracy: 0.9568 - val_loss: 0.2595 - val_accuracy: 0.9231\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.1779 - accuracy: 0.9624 - val_loss: 0.2528 - val_accuracy: 0.9304\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1684 - accuracy: 0.9660 - val_loss: 0.2491 - val_accuracy: 0.9304\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.1550 - accuracy: 0.9669 - val_loss: 0.2510 - val_accuracy: 0.9267\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.1472 - accuracy: 0.9660 - val_loss: 0.2442 - val_accuracy: 0.9304\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.1498 - accuracy: 0.9688 - val_loss: 0.2759 - val_accuracy: 0.9158\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.1444 - accuracy: 0.9679 - val_loss: 0.2437 - val_accuracy: 0.9267\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 0.1379 - accuracy: 0.9725 - val_loss: 0.2384 - val_accuracy: 0.9267\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.1279 - accuracy: 0.9725 - val_loss: 0.2357 - val_accuracy: 0.9267\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.1242 - accuracy: 0.9725 - val_loss: 0.2343 - val_accuracy: 0.9267\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1218 - accuracy: 0.9743 - val_loss: 0.2438 - val_accuracy: 0.9231\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.1139 - accuracy: 0.9752 - val_loss: 0.2390 - val_accuracy: 0.9231\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1089 - accuracy: 0.9752 - val_loss: 0.2349 - val_accuracy: 0.9231\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1067 - accuracy: 0.9734 - val_loss: 0.2359 - val_accuracy: 0.9231\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1087 - accuracy: 0.9725 - val_loss: 0.2286 - val_accuracy: 0.9267\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.9761 - val_loss: 0.2203 - val_accuracy: 0.9267\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0968 - accuracy: 0.9743 - val_loss: 0.2251 - val_accuracy: 0.9267\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0981 - accuracy: 0.9743 - val_loss: 0.2225 - val_accuracy: 0.9267\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9770 - val_loss: 0.2155 - val_accuracy: 0.9304\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1070 - accuracy: 0.9725 - val_loss: 0.2280 - val_accuracy: 0.9267\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.1006 - accuracy: 0.9761 - val_loss: 0.1915 - val_accuracy: 0.9377\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9780 - val_loss: 0.1934 - val_accuracy: 0.9341\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0835 - accuracy: 0.9807 - val_loss: 0.1879 - val_accuracy: 0.9377\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0819 - accuracy: 0.9789 - val_loss: 0.1974 - val_accuracy: 0.9341\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 0.9780 - val_loss: 0.1853 - val_accuracy: 0.9414\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0774 - accuracy: 0.9826 - val_loss: 0.1845 - val_accuracy: 0.9414\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0771 - accuracy: 0.9816 - val_loss: 0.1890 - val_accuracy: 0.9487\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.1860 - val_accuracy: 0.9451\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0736 - accuracy: 0.9826 - val_loss: 0.1821 - val_accuracy: 0.9487\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0729 - accuracy: 0.9826 - val_loss: 0.1944 - val_accuracy: 0.9487\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0685 - accuracy: 0.9826 - val_loss: 0.1899 - val_accuracy: 0.9524\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0688 - accuracy: 0.9835 - val_loss: 0.1966 - val_accuracy: 0.9487\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0623 - accuracy: 0.9844 - val_loss: 0.1927 - val_accuracy: 0.9487\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0609 - accuracy: 0.9853 - val_loss: 0.1833 - val_accuracy: 0.9560\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0623 - accuracy: 0.9862 - val_loss: 0.1835 - val_accuracy: 0.9560\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0574 - accuracy: 0.9844 - val_loss: 0.1796 - val_accuracy: 0.9560\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0538 - accuracy: 0.9890 - val_loss: 0.1894 - val_accuracy: 0.9524\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0570 - accuracy: 0.9881 - val_loss: 0.1777 - val_accuracy: 0.9560\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 0.1786 - val_accuracy: 0.9560\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0487 - accuracy: 0.9890 - val_loss: 0.1782 - val_accuracy: 0.9560\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0462 - accuracy: 0.9908 - val_loss: 0.1862 - val_accuracy: 0.9524\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9899 - val_loss: 0.1870 - val_accuracy: 0.9524\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0492 - accuracy: 0.9890 - val_loss: 0.1697 - val_accuracy: 0.9560\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0390 - accuracy: 0.9917 - val_loss: 0.1730 - val_accuracy: 0.9560\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0437 - accuracy: 0.9890 - val_loss: 0.1790 - val_accuracy: 0.9560\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.1854 - val_accuracy: 0.9560\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 0.1837 - val_accuracy: 0.9560\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 0.1942 - val_accuracy: 0.9524\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0344 - accuracy: 0.9917 - val_loss: 0.1807 - val_accuracy: 0.9560\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0299 - accuracy: 0.9927 - val_loss: 0.1966 - val_accuracy: 0.9524\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0286 - accuracy: 0.9936 - val_loss: 0.1965 - val_accuracy: 0.9597\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0359 - accuracy: 0.9927 - val_loss: 0.2083 - val_accuracy: 0.9597\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0278 - accuracy: 0.9954 - val_loss: 0.1981 - val_accuracy: 0.9597\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0326 - accuracy: 0.9936 - val_loss: 0.1945 - val_accuracy: 0.9597\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.2037 - val_accuracy: 0.9597\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0322 - accuracy: 0.9945 - val_loss: 0.1674 - val_accuracy: 0.9634\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0197 - accuracy: 0.9954 - val_loss: 0.1918 - val_accuracy: 0.9597\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0202 - accuracy: 0.9963 - val_loss: 0.1914 - val_accuracy: 0.9560\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.1897 - val_accuracy: 0.9634\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0222 - accuracy: 0.9982 - val_loss: 0.1889 - val_accuracy: 0.9524\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.2041 - val_accuracy: 0.9560\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 0.1959 - val_accuracy: 0.9560\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.2057 - val_accuracy: 0.9560\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9954 - val_loss: 0.1966 - val_accuracy: 0.9560\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.1866 - val_accuracy: 0.9597\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 0.1835 - val_accuracy: 0.9597\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0115 - accuracy: 0.9982 - val_loss: 0.1798 - val_accuracy: 0.9597\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.1884 - val_accuracy: 0.9560\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9982 - val_loss: 0.2030 - val_accuracy: 0.9560\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.1852 - val_accuracy: 0.9597\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.1865 - val_accuracy: 0.9560\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.1888 - val_accuracy: 0.9597\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.1920 - val_accuracy: 0.9597\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.1910 - val_accuracy: 0.9597\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9597\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9560\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.2082 - val_accuracy: 0.9560\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.2279 - val_accuracy: 0.9524\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9487\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.2283 - val_accuracy: 0.9524\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.2213 - val_accuracy: 0.9524\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9524\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.2157 - val_accuracy: 0.9524\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9560\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-51b7119b7ba3>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# plot accuracy/error for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# evaluate model on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-51b7119b7ba3>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'set_ylabel'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Music Instrument/Indian Music Inst/IndianInst.pb\")"
      ],
      "metadata": {
        "id": "JEnbMSHVUBal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6c296b-7d4a-4ec4-b551-bd3b571eb051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load your saved model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Music Instrument/IndianInst.pb')\n",
        "\n",
        "# Convert the model to a TFLite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Disable experimental lowering of tensor list ops\n",
        "converter.experimental_new_converter = True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to a file\n",
        "with open('/content/drive/MyDrive/Music Instrument/Indian Music Inst/IndianInst.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "o-THYBF1TTlM",
        "outputId": "f536315c-ec2e-487e-cead-d35af55b7944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-df091efed305>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_lower_tensor_list_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Save the TFLite model to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \"\"\"\n\u001b[0;32m-> 1373\u001b[0;31m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       graph_def, input_tensors, output_tensors = (\n\u001b[0;32m-> 1353\u001b[0;31m           self._convert_keras_to_saved_model(temp_dir))\n\u001b[0m\u001b[1;32m   1354\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         return super(TFLiteKerasModelConverterV2,\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_keras_to_saved_model\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       graph_def, input_tensors, output_tensors = self._load_saved_model(\n\u001b[1;32m   1300\u001b[0m           self.saved_model_dir, self._saved_model_tags)\n\u001b[0;32m-> 1301\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m    967\u001b[0m                         ckpt_options, options, filters)\n\u001b[1;32m    968\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     self._concrete_functions = (\n\u001b[0;32m--> 157\u001b[0;31m         function_deserialization.load_function_def_library(\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mlibrary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0msaved_object_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# import).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       func_graph = function_def_lib.function_def_to_graph(\n\u001b[0m\u001b[1;32m    417\u001b[0m           \u001b[0mfdef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m           \u001b[0mstructured_input_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructured_input_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec)\u001b[0m\n\u001b[1;32m    114\u001b[0m     ]\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0m_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36m_set_handle_data\u001b[0;34m(func_graph, fdef)\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;31m# saved in `handle_data`. Previously, the shape of the resource handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;31m# was set to `None`. Correct both shapes here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m   for tensor, arg_def in itertools.chain(\n\u001b[0m\u001b[1;32m    314\u001b[0m       \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       zip(func_graph.outputs, fdef.signature.output_arg)):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Music Instrument/IndianInst.pb')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "id": "23f0CSVxfNms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a14069-d64e-4dfd-e75c-a4641323b1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 130, 64)           26880     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,714\n",
            "Trainable params: 64,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()"
      ],
      "metadata": {
        "id": "ej8j3OBK61H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_segments=5\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"
      ],
      "metadata": {
        "id": "Y32mfpfPbS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)"
      ],
      "metadata": {
        "id": "xdlxrG7IbKa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "l8IrdoNNh-SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "import librosa\n",
        "\n",
        "audio_file = '/content/drive/MyDrive/Music Instrument/Indian Music Inst/Harmonium/Madhya_Teentaal_Lehra_Kirwani_C%23_Live_Harmonium_80bpm_108_cycles.m4a'\n",
        "\n",
        "audio_file, sr = librosa.load(audio_file)\n",
        "\n",
        "mfcc=librosa.feature.mfcc(y=audio_file, sr=SAMPLE_RATE, n_mfcc=40)\n",
        "mfcc = mfcc.T\n",
        "\n",
        "data_processed =mfcc\n",
        "\n",
        "data_processed = np.expand_dims(data_processed, axis=0)\n",
        "data_padded = pad_sequences(data_processed, maxlen=130, padding='post', truncating='post')\n",
        "prediction = model.predict(data_padded)\n",
        "\n",
        "\n",
        "class_labels = ['0 Harmonium', '1 Tabla', '2 Sitar', '3 Flute', '4 Dhol Tasha', '5 BG Noise']\n",
        "class_idx = np.argmax(prediction, axis=1)[0]\n",
        "print(class_idx)\n",
        "class_label = class_labels[class_idx]\n",
        "\n",
        "print(f'Predicted genre: {class_label}')"
      ],
      "metadata": {
        "id": "NEKdhLy57Qv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3437fa4-c196-4baf-df53-fb6ecc92ec1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-22934b4907cf>:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio_file, sr = librosa.load(audio_file)\n",
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "0\n",
            "Predicted genre: 0 Harmonium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zv9tvnwsnGyb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}